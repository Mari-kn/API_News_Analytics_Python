{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b8edb20",
   "metadata": {
    "papermill": {
     "duration": 0.006337,
     "end_time": "2024-07-26T18:10:31.500292",
     "exception": false,
     "start_time": "2024-07-26T18:10:31.493955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Project for analyzing news about \"Subject\", using the Guardian Media Group API and Python programming language, identify any\n",
    "unusual events in the time series, and investigate the cause of these unusual events. For using this code, you must replace \"subject\" with your query. Also enter your own API-Key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbba85a",
   "metadata": {
    "papermill": {
     "duration": 0.005329,
     "end_time": "2024-07-26T18:10:31.511575",
     "exception": false,
     "start_time": "2024-07-26T18:10:31.506246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1- Extract information about subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213e1948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T18:10:31.524625Z",
     "iopub.status.busy": "2024-07-26T18:10:31.524211Z",
     "iopub.status.idle": "2024-07-26T18:10:31.761578Z",
     "shell.execute_reply": "2024-07-26T18:10:31.760335Z"
    },
    "papermill": {
     "duration": 0.246955,
     "end_time": "2024-07-26T18:10:31.764163",
     "exception": false,
     "start_time": "2024-07-26T18:10:31.517208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve articles.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Fetch articles about subject\n",
    "def get_subject_articles(api_key, page_size=200): \n",
    "    # based on default behavior of the Guardian API, it limits the number of results returned per request.\n",
    "    # by default, the API returns 10 results per request unless specified otherwise. Based on my test, The max page_size in 4/18/2024 could be 200!\n",
    "    base_url = \"https://content.guardianapis.com/search\"\n",
    "    params = {\n",
    "        \"q\": \"Subject\",  # Enter your own query\n",
    "        \"api-key\": api_key,\n",
    "        \"page-size\": page_size  # specify the number of results per page\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200: #success\n",
    "        data = response.json()\n",
    "        return data['response']['results']\n",
    "    else:\n",
    "        print(\"Failed to retrieve articles.\")\n",
    "        return []\n",
    "\n",
    "api_key = #\"Enter your own API-Key here\"\n",
    "subject_articles = get_subject_articles(api_key)\n",
    "\n",
    "#print subject articles\n",
    "for result in subject_articles:\n",
    "    print(\"Title:\", result['webTitle'])\n",
    "    print(\"URL:\", result['webUrl'])\n",
    "    print(\"Publication Date:\", result['webPublicationDate'])\n",
    "    print(\"Section Name:\", result['sectionName'])\n",
    "    print(\"---------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f55aa",
   "metadata": {
    "papermill": {
     "duration": 0.005609,
     "end_time": "2024-07-26T18:10:31.775872",
     "exception": false,
     "start_time": "2024-07-26T18:10:31.770263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2- Count the number of articles about subject since 01.01.2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aed8c3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T18:10:31.790618Z",
     "iopub.status.busy": "2024-07-26T18:10:31.789814Z",
     "iopub.status.idle": "2024-07-26T18:10:31.799456Z",
     "shell.execute_reply": "2024-07-26T18:10:31.798382Z"
    },
    "papermill": {
     "duration": 0.019354,
     "end_time": "2024-07-26T18:10:31.801813",
     "exception": false,
     "start_time": "2024-07-26T18:10:31.782459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles about subject since 01.01.2018:\n"
     ]
    }
   ],
   "source": [
    "# based on API limitation, we have just 200 articles about subject, and the min date of them is 2022-02-17, \n",
    "# as it's becuase of API limitation, I already write a code for filter articles to be after 01.01.2018\n",
    "# our API is Developer version, we can order commercial API to have more articles\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "# convert string to datetime\n",
    "def convert_to_datetime(date_string):\n",
    "    return datetime.strptime(date_string , '%Y-%m-%dT%H:%M:%SZ' )\n",
    "    \n",
    "# count num of subject articles for each date \n",
    "def count_articles_by_date(articles):\n",
    "    article_counts = defaultdict(int)\n",
    "    for article in articles:\n",
    "        publication_date = datetime.strptime(article['webPublicationDate'], \"%Y-%m-%dT%H:%M:%SZ\").date()\n",
    "        article_counts[publication_date] += 1\n",
    "    return article_counts\n",
    "\n",
    "subject_articles_since_2018 = [article for article in subject_articles\n",
    "                                      if convert_to_datetime(article['webPublicationDate']) > convert_to_datetime('2018-01-01T00:00:00Z')]\n",
    "article_counts = count_articles_by_date(subject_articles_since_2018)\n",
    "print(\"Number of articles about subject since 01.01.2018:\")\n",
    "for date, count in sorted(article_counts.items()):\n",
    "    print(f\"{date}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28426bb8",
   "metadata": {
    "papermill": {
     "duration": 0.005763,
     "end_time": "2024-07-26T18:10:31.813565",
     "exception": false,
     "start_time": "2024-07-26T18:10:31.807802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3. Calculate the average of all days for the above-mentioned period from “No. of articles”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df26301c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T18:10:31.827470Z",
     "iopub.status.busy": "2024-07-26T18:10:31.826778Z",
     "iopub.status.idle": "2024-07-26T18:10:32.248910Z",
     "shell.execute_reply": "2024-07-26T18:10:32.247456Z"
    },
    "papermill": {
     "duration": 0.431389,
     "end_time": "2024-07-26T18:10:32.250853",
     "exception": true,
     "start_time": "2024-07-26T18:10:31.819464",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     total_articles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(article_counts\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_articles \u001b[38;5;241m/\u001b[39m total_days\n\u001b[0;32m---> 10\u001b[0m average_articles_per_day \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_average\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticle_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage_articles_per_day : \u001b[39m\u001b[38;5;124m\"\u001b[39m,average_articles_per_day)\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mcalculate_average\u001b[0;34m(article_counts)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_average\u001b[39m(article_counts):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin date: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marticle_counts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax date: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mmax\u001b[39m(article_counts\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m      6\u001b[0m     total_days \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mmax\u001b[39m(article_counts\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m(article_counts\u001b[38;5;241m.\u001b[39mkeys()))\u001b[38;5;241m.\u001b[39mdays \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# if I had complete output from API, the correct code is that we count number of days from 01.01.2018 till now and use it as divisor\n",
    "# but now I just count num of days between min and max dates that we have article\n",
    "def calculate_average(article_counts):\n",
    "    print(\"min date: \", min(article_counts.keys()))\n",
    "    print(\"max date: \", max(article_counts.keys()))\n",
    "    total_days = (max(article_counts.keys()) - min(article_counts.keys())).days + 1\n",
    "    total_articles = sum(article_counts.values())\n",
    "    return total_articles / total_days\n",
    "\n",
    "average_articles_per_day = calculate_average(article_counts)\n",
    "print(\"average_articles_per_day : \",average_articles_per_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ed82c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "4. In which section are most articles written?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af6332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T18:09:33.112401Z",
     "iopub.status.busy": "2024-07-26T18:09:33.112043Z",
     "iopub.status.idle": "2024-07-26T18:09:33.120428Z",
     "shell.execute_reply": "2024-07-26T18:09:33.119403Z",
     "shell.execute_reply.started": "2024-07-26T18:09:33.112373Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate section with most articles\n",
    "def find_most_common_section(articles):\n",
    "    section_counts = defaultdict(int)\n",
    "    for article in articles:\n",
    "        section_counts[article['sectionName']] += 1\n",
    "        most_common_section = max(section_counts, key=section_counts.get)\n",
    "    return (most_common_section , section_counts[most_common_section])\n",
    "\n",
    "most_common_section = find_most_common_section(subject_articles_since_2018)\n",
    "print(\"most common section since 01.2018: \" , most_common_section[0],\" with \",most_common_section[1] , \" Articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce88599",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "5. Show the evolution of the \"No. of articles\" over time for the above period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfad85b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T18:09:33.122400Z",
     "iopub.status.busy": "2024-07-26T18:09:33.121720Z",
     "iopub.status.idle": "2024-07-26T18:09:33.624026Z",
     "shell.execute_reply": "2024-07-26T18:09:33.622815Z",
     "shell.execute_reply.started": "2024-07-26T18:09:33.122364Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I use line chart becauseas we are looking for trend\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_article_counts_interactive(article_counts):\n",
    "    dates = sorted(article_counts.keys())\n",
    "    counts = [article_counts[date] for date in dates]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=dates, y=counts, mode='lines+markers', name='No. of Articles'))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Evolution of No. of Articles about subject (01.01.2018 - Today)\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"No. of Articles\",\n",
    "        xaxis=dict(tickangle=45),\n",
    "        hovermode=\"x\",\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "plot_article_counts_interactive(article_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef433f2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "6. Are there any unusual events in the time series under investigation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154f293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T18:09:33.625686Z",
     "iopub.status.busy": "2024-07-26T18:09:33.625373Z",
     "iopub.status.idle": "2024-07-26T18:09:33.666833Z",
     "shell.execute_reply": "2024-07-26T18:09:33.665587Z",
     "shell.execute_reply.started": "2024-07-26T18:09:33.625658Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Extract x and y data for the box plot\n",
    "x_data = list(article_counts.keys())\n",
    "y_data = list(article_counts.values())\n",
    "\n",
    "# Create the box plot\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Box(\n",
    "    y=y_data,\n",
    "    name='Article Counts',\n",
    "    hoverinfo='y+text',  # Display y-value and custom text on hover\n",
    "    text=x_data,          # Custom text (date) to display on hover\n",
    "    customdata=x_data     # Additional data (date) to be used in hover labels\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Box Plot of Article Counts since 01.01.2018\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Number of Articles\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b606113d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T18:09:33.668467Z",
     "iopub.status.busy": "2024-07-26T18:09:33.668151Z",
     "iopub.status.idle": "2024-07-26T18:09:33.680690Z",
     "shell.execute_reply": "2024-07-26T18:09:33.679481Z",
     "shell.execute_reply.started": "2024-07-26T18:09:33.668440Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate Q1 and Q3\n",
    "counts_sorted = sorted(article_counts.values())\n",
    "q1 = np.percentile(counts_sorted, 25)\n",
    "q3 = np.percentile(counts_sorted, 75)\n",
    "\n",
    "print(\"Q1 (first quartile):\", q1)\n",
    "print(\"Q3 (third quartile):\", q3)\n",
    "\n",
    "# Calculate interquartile range (IQR)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Identify outliers\n",
    "outliers = [count for count in article_counts.values() if count < q1 - 1.5 * iqr or count > q3 + 1.5 * iqr]\n",
    "outlier_dates = []\n",
    "if outliers:\n",
    "    print(\"Unusual events detected:\")\n",
    "    for date, count in article_counts.items():\n",
    "        if count in outliers:\n",
    "            outlier_dates.append(str(date))\n",
    "            print(f\"Date: {date}, Number of Articles: {count}\")\n",
    "else:\n",
    "    print(\"No unusual events detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b16e0ad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "7. If so, show these. Why are these unusual?\n",
    "This code calculates Q1 and Q3 of the number of articles per day and identifies any unusual events as outliers beyond 1.5 times the interquartile range.\n",
    "In statistical analysis, outliers are data points that significantly differ from other observations in a dataset and may indicate anomalies, errors, or rare events. These outliers could be unusual in the context of the dataset being analyzed.Outliers could represent days with an unusually high or low number of articles compared to the rest of the dataset. These deviations from the typical pattern may warrant further investigation to understand the underlying reasons, such as major events or errors in data collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7becd629",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "8. Based on question one. Show the cause of the unusual event.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d2d8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T18:09:33.682591Z",
     "iopub.status.busy": "2024-07-26T18:09:33.682262Z",
     "iopub.status.idle": "2024-07-26T18:09:33.941251Z",
     "shell.execute_reply": "2024-07-26T18:09:33.940230Z",
     "shell.execute_reply.started": "2024-07-26T18:09:33.682564Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "subject_articles_Unusual = [d for d in subject_articles if d['webPublicationDate'][0:10] in outlier_dates]\n",
    "\n",
    "# Dictionary to store article texts by date\n",
    "articles_by_date = {}\n",
    "\n",
    "# Fetch and store article texts by date\n",
    "for result in subject_articles_Unusual:\n",
    "    # Fetch the HTML content of the page\n",
    "    response = requests.get(result['webUrl'])\n",
    "    html_content = response.text\n",
    "\n",
    "    # Parse the HTML using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Find the article content\n",
    "    article_content = soup.find(\"div\", class_=\"dcr-ch7w1w\")\n",
    "\n",
    "    # Extract and store the text\n",
    "    if article_content:\n",
    "        article_text = article_content.get_text()\n",
    "        publication_date = result['webPublicationDate'][0:10]\n",
    "        if publication_date not in articles_by_date:\n",
    "            articles_by_date[publication_date] = []\n",
    "        articles_by_date[publication_date].append(article_text)\n",
    "\n",
    "# Analyze article texts for each date\n",
    "for date, articles in articles_by_date.items():\n",
    "    print(\"Date:\", date)\n",
    "    all_text = ' '.join(articles)\n",
    "    # Tokenize the text (split by spaces)\n",
    "    words = all_text.split()\n",
    "    # Count the occurrences of each word\n",
    "    word_counts = Counter(words)\n",
    "    # Print the most common words\n",
    "    for word, count in word_counts.most_common(70):\n",
    "        if word not in ['the','of','in','and','to','a','on','that','was','for','with','is',\n",
    "                        'by','as','has','said','will','his','he','be','I','it','at','been',\n",
    "                        'had','an','this','are','this','have','–','were','from','not','our',\n",
    "                        'about','new','New','more','The', 'their','which','who','all','its','we',\n",
    "                        'one','also','would','or','but','do','so', 'in','In','But','out','It','see',\n",
    "                        'We','like','content','they','these','some','than','after','For','may','two',\n",
    "                        'other','can','see'\n",
    "                       ] :\n",
    "           print(f\"{word}: {count}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.226713,
   "end_time": "2024-07-26T18:10:32.677262",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-26T18:10:28.450549",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
